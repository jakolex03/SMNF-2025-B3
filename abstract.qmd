---
title: "Titel"
editor: visual
authors: Jakob, Tigran, Paul
date: today
format: 
  html: 
    number-sections: true
    citeproc: true
  pdf: 
    number-sections: true
    papersize: a4
    fontsize: 12pt
    toc: true
    citeproc: true
    
bibliography: literatur.bib
csl: apa.csl
---

**GitHub Repository:** <https://github.com/jakolex03/SMNF-2025-B3>

**Aktueller** **Git Commit Hash:**

```{r}
#| label: Commit Hash
#| echo: false
commit_hash <- system("git rev-parse --short=7 HEAD", intern = TRUE)
commit_hash

```

Code of Conduct:

Beim Meinungsverschiedenheiten reden wir sachlich darüber und versuchen Kompromisse zu finden. Die Aufteilung der Arbeit ist eher nicht so fair. Paul und ich (Jakob) machen alles, währrend Anselm sich wahrscheinlich exmatrikuliert und Tigran sich gar nicht mehr gemeldet hat. Wir versuchen und rechtzeitig vorzubereiten und darauf zu achten Termine einzuhalten, die erste Präsentation übernahmen Paul und Jakob, sowohl Gestaltung der Folien als auch das Vortragen. Wir sind uns sehr bewusst wie wichtig Datenschutz ist und werden erhobene Daten nur im Zusammenhang mit unserer Studie verwenden und versuchen Teilnehmer zu gut es geht anonym zu halten. Die Nutzung von Künstlicher Intelligenz wird von uns klar gekennzeichnet.

# Einleitung:

# Literaturübersicht:

Wir benutzen für unsere Studie als Literatur die folgenden Werke: "Verunsicherte Öffentlichkeit" ([@bertelsmann2024]) "The Implied Truth Effect"([@pennycook2021]) und "The Economics of Fake News"([@kshetri2017]). "Verunsicherte Öffentlichkeit trifft unser Thema ziemlich genau. Es geht in der Studie um die Verbreitung von Desinformationen im Jahre 2024, kurz vor den Wahlen in den USA und Deutschland. Dabei wird erforscht wie gut Menschen Desinformation erkennen. Außerdem wird die Wichtigkeit guter Medienkompetenz betont und Ansätze vorgeschlagen, wie man Desinformation mit KI kennzeichnen könnte, damit Menschen diese einfach erkennen können und sie sich nicht viral verbreiten. Das passt sehr gut zu unserer übergeordneten Forschungsfrage, welche sich damit beschäftigt, wie man KI am besten zum Erkennen und Kennzeichnen von Misinformation auf Social Media benutzen kann. Als nächstes benutzen wir: "The Implied Truth Effect". Diese Studie untersucht die Wirkung der Markierung von Desinformationen und untersucht die Hypothese, welche sagt, dass durch eine Markierung der "Implied Truth Effect entsteht und Nutzer davon ausgehen, dass dann alles, was nicht gekennzeichnet wird, wahr ist. Die Studie stellte fest, dass nicht markierte, falsche Meldungen ungewollt als glaubwürdig wahrgenommen wurden. Das sollten wir bei unserer Studie berücksichtigen um die bestmöglichen Ansätze zu entwickeln, die auch dieses Problem verhindern. Als letztes nutzen wir "The Economics of Fake News". Kshetri und Voas untersuchen in dieser Studie die Kosten und den Nutzen der Verbreitung von Fake News. Außerdem die wirtschaftlichen, politischen und sozialen Folgen dieser Fehlinformationen. Die Verfasser\*innen bringen vor, dass Produzenten, Konsumenten und Plattformen ein selbstverstärkendes System bilden, das nur schwer zu durchbrechen ist. Sie bieten unterschiedliche Strategien an, um dieses System zu unterbrechen und die Kosten-Nutzen-Struktur der Verbreitung von Fake News zu reduzieren. Für uns ist es entscheident, dass wir die Beweggründe und Vorzüge der Verbreitung von Fake News verstehen.

# Methode:

# Ergebnisse:

# Diskussion:

# Literaturverzeichnis:

::: {#refs}
:::
